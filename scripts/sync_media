#!/usr/bin/env bash
set -e

# FIXME: Add slugs for puzzles that require extra large assets
EXTRA_LARGE_ASSET_SLUGS=()

PYJS_IMAGE=nikolaik/python-nodejs:python3.9-nodejs16@sha256:e858a798bf7ec2f4174e7ff756e6c83eb123b687e451a9bf8aced59fa9d2be75
large=
full=
if [ "$1" = "--large" ]; then
  large=1
  shift 1
fi
if [ "$1" = "--full" ]; then
  full=1
  shift 1
fi
if [ ! -z "$2" ] ; then
  CREDS_FILE="$(perl -e "use Cwd 'abs_path'; print abs_path('${2}')")"
fi
REAL_SOURCE="$(perl -e "use Cwd 'abs_path'; print abs_path('${BASH_SOURCE}')")"
cd "$(dirname "$(dirname "${REAL_SOURCE}")")"

# Usage: ./scripts/sync_media [--large] [--full] [DEST volume or directory] [gdrive-creds.json]
# WARNING: This will delete existing files in `DEST/drive` that are not in Google Drive.
# This will sync media files from Google Drive and update the mapping of hashes.
#
# The namespace of both folders is unified; the top level folder name is ignored in
# doing the mapping.


#
# Set up creds and parse arguments
#
CREDS_FILE="${CREDS_FILE:-$(pwd)/gdrive-creds.json}"
# must be absolute path or volume mount
SYNC_LOCATION="${1:-${HOME}/srv}"
if [[ "${SYNC_LOCATION}" = "dev" ]] ; then
    SYNC_LOCATION="$(basename $(pwd))_srv_dev"
fi

if [[ ! -f "${CREDS_FILE}" ]] ; then
  >&2 echo "Could not find credentials ${CREDS_FILE}"
  exit 1
fi
if [[ "${SYNC_LOCATION}" = /* ]] ; then
  if [ ! -d "${SYNC_LOCATION}" ] ; then
    >&2 echo "Could not find directory ${SYNC_LOCATION}"
    exit 1
  fi
else
  # docker will print an error message if the volume does not exist
  docker volume inspect -- "${SYNC_LOCATION}" >/dev/null || exit 1
fi

#
# Remove deprecated layout if it exists
#
>&2 echo "Checking for and deleting old layout..."
docker run --rm -i \
  -v "${SYNC_LOCATION}:/sync_mount" \
  "${PYJS_IMAGE}" \
  sh -c "python3 -" <<-EOF
from pathlib import Path
import shutil

# paths
SRV = Path("/sync_mount")
DRIVE = SRV / "drive"

puzzles = DRIVE / "Puzzles"

if puzzles.exists():
  shutil.rmtree(DRIVE)

EOF

#
# Sync most assets
#
>&2 echo "Syncing Google Drive to local filesystem... [${SYNC_LOCATION}]"
# first, detect owner from container's pov (rootless maps UIDs)
UIDGID="$(docker run --rm -i \
  -v "${SYNC_LOCATION}:/sync_mount" \
  --entrypoint stat \
  rclone/rclone:1.58.1 \
  -c '%u:%g' /sync_mount
)"
docker run --rm -i \
  -u "${UIDGID}" \
  -v "$(pwd)/scripts/rclone.conf:/rclone.conf:ro" \
  -v "${CREDS_FILE}:/gdrive-creds.json:ro" \
  -v "${SYNC_LOCATION}:/sync_mount" \
  rclone/rclone:1.58.1 \
  -v sync gdrive:/ /sync_mount/drive/Assets/ \
  --config /rclone.conf --fast-list

#
# Sync large puzzle assets ( > 20MB )
#
if [ ! -z "$large" ] || [ ! -z "$full" ] ; then
  >&2 echo "Syncing large puzzle assets from Google Drive to local filesystem... [${SYNC_LOCATION}]"
  docker run --rm -i \
    -u "${UIDGID}" \
    -v "$(pwd)/scripts/rclone.conf:/rclone.conf:ro" \
    -v "${CREDS_FILE}:/gdrive-creds.json:ro" \
    -v "${SYNC_LOCATION}:/sync_mount" \
    rclone/rclone:1.58.1 \
    -v sync large-asset:/ "/sync_mount/drive/Large Assets/" \
    --config /rclone.conf --fast-list
fi

#
# Sync extra large puzzle assets ( > 1GB )
# also special handling for converting to servable form
#
if [ ! -z "$full" ] ; then
  >&2 echo "Syncing extra large puzzle assets from Google Drive to local filesystem... [${SYNC_LOCATION}]"
  docker run --rm -i \
    -u "${UIDGID}" \
    -v "$(pwd)/scripts/rclone.conf:/rclone.conf:ro" \
    -v "${CREDS_FILE}:/gdrive-creds.json:ro" \
    -v "${SYNC_LOCATION}:/sync_mount" \
    rclone/rclone:1.58.1 \
    -v sync extra-large-asset:/ "/sync_mount/drive/Extra Large Assets/" \
    --config /rclone.conf --fast-list
  >&2 echo "Hashing assets and updating extra large assets..."
  docker run --rm -i \
    -v "${SYNC_LOCATION}:/sync_mount" \
    "${PYJS_IMAGE}" \
    sh <<-EOF
for slug in $EXTRA_LARGE_ASSET_SLUGS; do
  echo "Updating and extracting \${slug}..."
  filename="/sync_mount/drive/Extra Large Assets/\${slug}.zip"
  if [ -f "\${filename}" ]; then
    sha="\$(sha256sum "\${filename}" | cut -d' ' -f1)"
    mkdir -p "/sync_mount/media/\${slug}/\${sha}"
    unzip -qod "/sync_mount/media/\${slug}/\${sha}" "\${filename}"
    echo "\${slug}/\${sha}" > "/sync_mount/\${slug}.txt"
  else
    >&2 echo "Could not find \${filename}. Skipping..."
  fi
done
EOF
fi

>&2 echo "Hashing assets and updating asset mapping..."
docker run --rm -i \
  -v "${SYNC_LOCATION}:/sync_mount" \
  "${PYJS_IMAGE}" \
  sh -c "pip install --no-input numpy Pillow pyyaml >/dev/null 2>/dev/null && python3 -" <<-EOF
import filecmp
import itertools
import os
from pathlib import Path
import shutil
import string
import subprocess
import sys
import tempfile

import numpy as np
from PIL import Image, ImageFilter
import yaml

# paths
SRV = Path("/sync_mount")
DRIVE = SRV / "drive"
MEDIA = SRV / "media"
MAPPING_FILENAME = SRV / "media_mapping.yaml"

# colors for glow
COLORS_BY_ROUND = {
  "FIXME": {
    "other": (255, 255, 255), # white
    "unsolved": (255, 255, 128), # bright yellow
    "solved": (128, 255, 255) # bright cyan,
  },
}
MARGIN = 0.05 # proportion buffer to add
GLOW_RADIUS = 8 # pixels

# drop privileges
stat_result = SRV.stat()
os.setregid(stat_result.st_gid, stat_result.st_gid)
os.setreuid(stat_result.st_uid, stat_result.st_uid)

# scan files and sha sums
ignorelist = set()
filemap = {}
hexdigits = set(string.hexdigits.lower())
allowed_exts = set([
  ".bmp",
  ".gif",
  ".ico",
  ".jpeg",
  ".jpg",
  ".png",
  ".svg",
  ".tif",
  ".tiff",
  ".webp",

  ".avi",
  ".f4v",
  ".flv",
  ".mkv",
  ".mov",
  ".mp4",
  ".swf",
  ".webm",
  ".wmv",

  ".aac",
  ".flac",
  ".m4a",
  ".mp3",
  ".wav",
  ".wma",

  ".csv",
  ".zip",
  ".pdf",
  ".txt",
])

def add_glow(fin, fout, color):
  src = np.array(Image.open(fin))
  if src.shape[-1] != 4:
    print(f"Warning: {fin} does not have an alpha channel and will not have glow", file=sys.stderr)
    Image.fromarray(src).save(fout)
    return
  ymargin = int(src.shape[0] * MARGIN)
  xmargin = int(src.shape[1] * MARGIN)
  img = np.zeros((src.shape[0] + 2*ymargin, src.shape[1] + 2*xmargin, 4), dtype=np.uint8)
  img[ymargin:img.shape[0]-ymargin, xmargin:img.shape[1]-xmargin] = src
  mask = np.array(img)
  mask[..., :3] = color[:3]
  if len(color) > 3:
    mask[..., 3] = (mask[..., 3] * (color[3] / 255)).astype(mask.dtype)
  mask = Image.fromarray(mask)
  blur = ImageFilter.GaussianBlur(radius=GLOW_RADIUS)
  blurred = mask.filter(blur)
  out = Image.alpha_composite(blurred, Image.fromarray(img))
  out.save(fout)

def add(src, sha, relative_to):
  'Adds src assuming sha is the precomputed hash. Returns whether the file was added/updated.'
  drive_relative = src.relative_to(relative_to)
  from_name = str(drive_relative.relative_to(drive_relative.parts[0]))
  to_name = f"{sha[0]}/{sha[1]}/{sha[2:]}{src.suffix}"
  dest = MEDIA / to_name
  filemap[from_name] = to_name
  dest.parent.mkdir(parents=True, exist_ok=True)
  if not (dest.exists() and filecmp.cmp(src, dest)):
    shutil.copyfile(src, dest)
    return True
  return False

def collect_hashes(root):
  for line in subprocess.check_output(
    ["find", root, "-type", "f", "-exec", "sha256sum", "-z", "{}", ";"],
    text=True,
  ).split("\0"):
    if not line:
      continue
    sha, src = line.split("  ", 1)
    src = Path(src)
    yield src, sha

with tempfile.TemporaryDirectory() as tmpdir:
  tmpdir = Path(tmpdir)
  transformed_dir = tmpdir / 'transformed'
  # convert glow icons for specific rounds
  for _round in ['FIXME']:
    base = DRIVE / 'Assets' / 'Rounds' / _round
    other_dir = base / 'other'
    if other_dir.is_dir():
      for asset in other_dir.iterdir():
        if asset.name.endswith("_GLOW.png"):
          ignorelist.add(asset.absolute())
          outfile = transformed_dir / asset.relative_to(DRIVE)
          outfile.parent.mkdir(parents=True, exist_ok=True)
          add_glow(asset, outfile, COLORS_BY_ROUND[_round]["other"])

    puzzles_dir = base / 'puzzles'
    if puzzles_dir.is_dir():
      for puzzle_dir in puzzles_dir.iterdir():
        if puzzle_dir.is_dir():
          default_icon = puzzle_dir / 'default.png'
          if default_icon.is_file():
            outdir = transformed_dir / default_icon.parent.relative_to(DRIVE)
            outdir.mkdir(parents=True, exist_ok=True)
            ignorelist.add(default_icon.absolute())
            add_glow(default_icon, outdir / 'unsolved.png', COLORS_BY_ROUND[_round]["unsolved"])
            add_glow(default_icon, outdir / 'solved.png', COLORS_BY_ROUND[_round]["solved"])
          else:
            # if there is no default, there probably exists solved/unsolved versions
            for asset in puzzle_dir.iterdir():
              asset_type = None
              if asset.name == "unsolved.png":
                asset_type = "unsolved"
              elif asset.name == "solved.png":
                asset_type = "solved"
              if not asset_type:
                continue
              ignorelist.add(asset.absolute())
              outfile = transformed_dir / asset.relative_to(DRIVE)
              outfile.parent.mkdir(parents=True, exist_ok=True)
              add_glow(asset, outfile, COLORS_BY_ROUND[_round][asset_type])

  # hash files
  new_count = 0
  total_count = 0
  for src, sha in itertools.chain(
    collect_hashes(transformed_dir),
    collect_hashes(DRIVE),
  ):
    if src.absolute() in ignorelist:
      continue
    assert all(c in hexdigits for c in sha)
    if src.suffix not in allowed_exts:
      continue
    if DRIVE in src.parents:
      relative_to = DRIVE
    else:
      assert transformed_dir in src.parents
      relative_to = transformed_dir
    if add(src, sha, relative_to):
      new_count += 1
    total_count += 1

  # write to YAML atomically
  map_fname = tmpdir / "map.yaml"
  with open(map_fname, "w") as f:
    yaml.dump({"media": filemap}, f)
  shutil.move(map_fname, MAPPING_FILENAME)
print(f"Finished syncing media files: {new_count} of {total_count} were new", file=sys.stderr)
EOF
